{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b7c068a8",
      "metadata": {
        "id": "b7c068a8"
      },
      "source": [
        "##### ARTI 560 - Computer Vision  \n",
        "## Image Classification using Transfer Learning\n",
        "\n",
        "### Overview\n",
        "\n",
        "**Transfer learning** is a machine learning technique where a model developed for one task is reused as the starting point for a different but related task. Instead of training a model from scratch, which can be time-consuming and require large datasets, transfer learning leverages the knowledge a pretrained model has already learned.\n",
        "\n",
        "#### Key Concepts\n",
        "\n",
        "1. **Pretrained Models**  \n",
        "   - Models trained on large benchmark datasets (e.g., ImageNet) can capture general features such as edges, textures, and shapes in images.\n",
        "   - Common pretrained models for image classification include **VGG16**, **ResNet**, **MobileNetV2**, and **EfficientNet**.\n",
        "\n",
        "2. **Feature Extraction**  \n",
        "   - The pretrained model is used as a fixed feature extractor.\n",
        "   - Only the final layers (classifier) are replaced and trained on the new dataset.\n",
        "\n",
        "3. **Fine-Tuning**  \n",
        "   - A more advanced approach where some of the pretrained layers are \"unfrozen\" and trained on the new dataset.\n",
        "   - Helps the model adapt more closely to the specific features of the new task.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this lab, we will apply transfer learning with a pretrained ResNetV2 on CIFAR-10, fine-tune the model, and examine its architecture and trainable layers.\n",
        "\n",
        "### Tools & Libraries\n",
        "- Python  \n",
        "- NumPy  \n",
        "- TensorFlow\n",
        "- Matplotlib  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9744d9c",
      "metadata": {
        "id": "d9744d9c"
      },
      "source": [
        "### Transfer Learning using a Pre-trained ResNet\n",
        "\n",
        "#### Steps:\n",
        "1. Load a pre-trained ResNet50V2 model from `keras.applications` with ImageNet weights, excluding the top classification layer.\n",
        "2. Resize the CIFAR-10 images to match the input size expected by ResNet (e.g., 224x224).\n",
        "3. Build a new Keras Sequential model by adding the existing `data_augmentation` layer, followed by a resizing layer for input to ResNet, the loaded ResNet base model (freezing its layers), a `GlobalAveragePooling2D` layer, and a new `Dense` classification head (with 10 output units) for CIFAR-10.\n",
        "4. Compile this model with an Adam optimizer, sparse categorical cross-entropy loss, and accuracy metrics, and train it on the preprocessed CIFAR-10 training data for a few epochs using early stopping callbacks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f1cdc73",
      "metadata": {
        "id": "9f1cdc73"
      },
      "source": [
        "#### Important: Pretrained model preprocessing\n",
        "\n",
        "Pretrained models (ImageNet weights) expect inputs to be preprocessed *exactly* like during ImageNet training.\n",
        "For ResNet50 in Keras, use:\n",
        "\n",
        "`tf.keras.applications.resnet50.preprocess_input(...)`\n",
        "\n",
        "If you skip this step, accuracy may drop close to random guessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9d683926",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "9d683926",
        "outputId": "77a52ce1-4363-4820-9110-8b162c4c31c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cifar10_resnet50v2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cifar10_resnet50v2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resizing (\u001b[38;5;33mResizing\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m20,490\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,585,290\u001b[0m (89.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,585,290</span> (89.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,490\u001b[0m (80.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> (80.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 134ms/step - accuracy: 0.6969 - loss: 0.8628 - val_accuracy: 0.8700 - val_loss: 0.3664 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 133ms/step - accuracy: 0.8033 - loss: 0.5673 - val_accuracy: 0.8752 - val_loss: 0.3570 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 133ms/step - accuracy: 0.8215 - loss: 0.5200 - val_accuracy: 0.8768 - val_loss: 0.3506 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 133ms/step - accuracy: 0.8264 - loss: 0.4980 - val_accuracy: 0.8770 - val_loss: 0.3645 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 133ms/step - accuracy: 0.8367 - loss: 0.4666 - val_accuracy: 0.8858 - val_loss: 0.3346 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Load CIFAR-10\n",
        "# -----------------------------\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "class_names = [\n",
        "    \"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
        "    \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"\n",
        "]\n",
        "\n",
        "# Keep labels as integers (SparseCategoricalCrossentropy)\n",
        "y_train = y_train.squeeze().astype(\"int64\")\n",
        "y_test  = y_test.squeeze().astype(\"int64\")\n",
        "\n",
        "# Convert images to float32\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test  = x_test.astype(\"float32\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Data augmentation\n",
        "# -----------------------------\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "], name=\"augmentation\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) Build ResNet50V2 backbone (pretrained)\n",
        "# -----------------------------\n",
        "resnet_base = ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "resnet_base.trainable = False  # freeze first (feature extractor)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Full model (preprocess inside model)\n",
        "# -----------------------------\n",
        "resnet_model = keras.Sequential([\n",
        "    layers.Input(shape=(32, 32, 3)),\n",
        "    data_augmentation,\n",
        "    layers.Resizing(224, 224, interpolation=\"bilinear\"),\n",
        "    layers.Lambda(preprocess_input),          # IMPORTANT: correct for ResNet50V2\n",
        "    resnet_base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(10)                          # logits\n",
        "], name=\"cifar10_resnet50v2\")\n",
        "\n",
        "resnet_model.summary()\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Compile + Train (frozen backbone)\n",
        "# -----------------------------\n",
        "resnet_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1),\n",
        "]\n",
        "\n",
        "history = resnet_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=34,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9f324d",
      "metadata": {
        "id": "5d9f324d"
      },
      "source": [
        "Let's test our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d7100739",
      "metadata": {
        "id": "d7100739",
        "outputId": "741869a4-6d40-4155-a0f9-d4f930d6584b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50V2 (frozen) test accuracy: 0.8841999769210815\n",
            "ResNet50V2 (frozen) test loss    : 0.33952605724334717\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------\n",
        "# 6) Test / Evaluate\n",
        "# -----------------------------\n",
        "test_loss, test_acc_r = resnet_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"ResNet50V2 (frozen) test accuracy:\", test_acc_r)\n",
        "print(\"ResNet50V2 (frozen) test loss    :\", test_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3ba34a",
      "metadata": {
        "id": "ab3ba34a"
      },
      "source": [
        "### Fine-tune ResNet\n",
        "\n",
        "In this step, we fine-tune the pretrained network by unfreezing the last layers and training with a small learning rate. This allows the model to better adapt to CIFAR-10 while preserving useful pretrained features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "62865dd3",
      "metadata": {
        "id": "62865dd3",
        "outputId": "04a8aced-f185-4a97-af77-fe64a1aca4fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable layers in backbone: 30 / 190\n",
            "Epoch 1/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 188ms/step - accuracy: 0.8027 - loss: 0.5721 - val_accuracy: 0.9054 - val_loss: 0.2696\n",
            "Epoch 2/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 186ms/step - accuracy: 0.8689 - loss: 0.3797 - val_accuracy: 0.9122 - val_loss: 0.2430\n",
            "Epoch 3/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 186ms/step - accuracy: 0.8954 - loss: 0.3022 - val_accuracy: 0.9180 - val_loss: 0.2304\n",
            "Epoch 4/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 186ms/step - accuracy: 0.9097 - loss: 0.2574 - val_accuracy: 0.9290 - val_loss: 0.2137\n",
            "Epoch 5/5\n",
            "\u001b[1m1324/1324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 186ms/step - accuracy: 0.9269 - loss: 0.2177 - val_accuracy: 0.9312 - val_loss: 0.1979\n",
            "ResNet50V2 (fine-tuned) test accuracy: 0.9283999800682068\n",
            "ResNet50V2 (fine-tuned) test loss    : 0.21251121163368225\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "#Fine-tune last layers\n",
        "# -----------------------------\n",
        "resnet_base.trainable = True\n",
        "for layer in resnet_base.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"Trainable layers in backbone:\", sum(l.trainable for l in resnet_base.layers), \"/\", len(resnet_base.layers))\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_ft = resnet_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=34,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss_ft, test_acc_ft = resnet_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"ResNet50V2 (fine-tuned) test accuracy:\", test_acc_ft)\n",
        "print(\"ResNet50V2 (fine-tuned) test loss    :\", test_loss_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3131f0",
      "metadata": {
        "id": "8e3131f0"
      },
      "source": [
        "### Compare the two models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d343160a",
      "metadata": {
        "id": "d343160a",
        "outputId": "eb8ac8f0-1c32-450d-d04a-dfa05fbf3692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet frozen test acc: 0.8841999769210815\n",
            "ResNet fine-tuned test acc: 0.9283999800682068\n"
          ]
        }
      ],
      "source": [
        "# Collect and compare accuracies (update if you rename variables)\n",
        "results = {\n",
        "    \"ResNet frozen test acc\": float(test_acc_r) if 'test_acc_r' in globals() else None,\n",
        "    \"ResNet fine-tuned test acc\": float(test_acc_ft) if 'test_acc_ft' in globals() else None,\n",
        "}\n",
        "for k,v in results.items():\n",
        "    print(f\"{k}: {v}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}